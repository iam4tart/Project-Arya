{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import operator\n",
    "import os\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import plotly as py\n",
    "tls.set_credentials_file(username='iam4tart',api_key='Docq9bPOpIqBxnDmPIxJ')\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import cufflinks as cf\n",
    "import IPython.display as ipd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'go': 483, 'safe': 5098, 'angry': 623, 'background': 1107, 'calm': 3020, 'unknown': 1169, 'happy': 543, 'no': 539, 'fearful': 1162, 'help': 588, 'stop': 535, 'yes': 501, 'None': 157, 'bacho': 583, 'scream': 352, 'gunshots': 10, 'glass break': 45}\n",
      "\n",
      "      keyword   stress environment  \\\n",
      "0          go    angry        safe   \n",
      "1  background     calm        safe   \n",
      "2     unknown    happy        safe   \n",
      "3          no  fearful        safe   \n",
      "4        help  fearful        safe   \n",
      "\n",
      "                                                path  \n",
      "0  EmoSpeech/go-safe-angry-20190731001623-d14a028...  \n",
      "1  EmoSpeech/background-safe-calm-20190709093534-...  \n",
      "2  EmoSpeech/unknown-safe-happy-1561964984.688572...  \n",
      "3  EmoSpeech/no-safe-fearful-20190712140008-d14a0...  \n",
      "4  EmoSpeech/help-safe-fearful-20190623190210-d14...  \n",
      "Total Number of samples:  5505\n"
     ]
    }
   ],
   "source": [
    "def get_files(path):\n",
    "    data_ = []\n",
    "    count = {}\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        labels = file.split(\"-\")[:3]\n",
    "        data = {\n",
    "            \"keyword\": labels[0],\n",
    "            \"stress\": labels[2],\n",
    "            \"environment\": labels[1],\n",
    "            \"path\": os.path.join(path, file)\n",
    "        }\n",
    "        for label in labels:\n",
    "            if label not in count.keys():\n",
    "                count[label] = 1\n",
    "            else:\n",
    "                count[label] += 1\n",
    "        data_.append(data)\n",
    "    if data_:\n",
    "        df = pd.DataFrame(data_)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['keyword', 'stress', 'environment', 'path'])\n",
    "    return data_, count, df\n",
    "\n",
    "path = 'EmoSpeech/'\n",
    "dataset, count, df = get_files(path)\n",
    "df_nopath = df.iloc[:, :-1]\n",
    "\n",
    "print(count)\n",
    "print()\n",
    "print(df.head())\n",
    "print(\"Total Number of samples: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, duration=3, sr=16000, n_mfcc=13, max_frames=150):\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    # Pad or truncate to a fixed number of frames\n",
    "    if mfccs.shape[1] < max_frames:\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, max_frames - mfccs.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfccs = mfccs[:, :max_frames]\n",
    "    return mfccs.T  # Transpose to have time along the columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['stress_encoded'] = label_encoder.fit_transform(df['stress'])\n",
    "df['environment_encoded'] = label_encoder.fit_transform(df['environment'])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X = np.array([extract_features(file) for file in df['path']])\n",
    "y_stress = to_categorical(df['stress_encoded'])\n",
    "y_env = to_categorical(df['environment_encoded'])\n",
    "X_train, X_test, y_stress_train, y_stress_test, y_env_train, y_env_test = train_test_split(X, y_stress, y_env, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define the neural network model\n",
    "# input_shape = X_train.shape[1:]\n",
    "# stress_output_classes = len(df['stress'].unique())\n",
    "# env_output_classes = len(df['environment'].unique())\n",
    "\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=input_shape),\n",
    "#     layers.LSTM(128, return_sequences=True),\n",
    "#     layers.LSTM(128),\n",
    "#     layers.Dense(stress_output_classes, activation='softmax', name='stress_output'),\n",
    "#     layers.Dense(env_output_classes, activation='softmax', name='env_output')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, {'stress_output': y_stress_train, 'env_output': y_env_train}, validation_data=(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test}), epochs=10)\n",
    "\n",
    "# # Evaluate the model\n",
    "# # Evaluate the model\n",
    "\n",
    "# print(model.evaluate(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test}))\n",
    "# # loss, stress_loss, env_loss, stress_accuracy, env_accuracy = model.evaluate(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_env)\n",
    "print(y_stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'calm' 'happy' 'fearful' 'None'] \n",
      " ['safe' 'scream' 'gunshots' 'glass break']\n"
     ]
    }
   ],
   "source": [
    "print(df['stress'].unique(),\"\\n\",df['environment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_path = 'House/go-scream-calm-20190713144915.wav'\n",
    "\n",
    "\n",
    "# # Extract features from the sample\n",
    "# sample_features = extract_features(sample_path)\n",
    "# sample_features = np.expand_dims(sample_features, axis=0)\n",
    "\n",
    "# # Predict stress and environment labels\n",
    "# stress_pred, env_pred = model.predict(sample_features)[0]\n",
    "\n",
    "# # Get the predicted labels\n",
    "# predicted_stress_index = np.argmax(stress_pred)\n",
    "# predicted_env_index = np.argmax(env_pred)\n",
    "# predicted_stress = label_encoder.inverse_transform([predicted_stress_index])[0]\n",
    "# predicted_env = label_encoder.inverse_transform([predicted_env_index])[0]\n",
    "\n",
    "# print(f'Predicted Stress: {predicted_stress}, Predicted Environment: {predicted_env}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0209 - loss: 1.8314 - val_accuracy: 0.0572 - val_loss: 1.2563\n",
      "Epoch 2/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 1.1733 - val_accuracy: 0.9310 - val_loss: 0.9511\n",
      "Epoch 3/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.8919 - val_accuracy: 0.9310 - val_loss: 0.7396\n",
      "Epoch 4/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.7036 - val_accuracy: 0.9310 - val_loss: 0.5969\n",
      "Epoch 5/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.5755 - val_accuracy: 0.9310 - val_loss: 0.5030\n",
      "Epoch 6/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.4897 - val_accuracy: 0.9310 - val_loss: 0.4411\n",
      "Epoch 7/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.4369 - val_accuracy: 0.9310 - val_loss: 0.3996\n",
      "Epoch 8/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.3949 - val_accuracy: 0.9310 - val_loss: 0.3714\n",
      "Epoch 9/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.3688 - val_accuracy: 0.9310 - val_loss: 0.3516\n",
      "Epoch 10/10\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.3590 - val_accuracy: 0.9310 - val_loss: 0.3376\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9322 - loss: 0.3356\n",
      "[0.3376360237598419, 0.9309718608856201]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "[0.03746269 0.03673195 0.8508643  0.07494114]\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network model\n",
    "input_shape = X_train.shape[1:]\n",
    "stress_output_classes = len(df['stress'].unique())\n",
    "env_output_classes = len(df['environment'].unique())\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv1D(128, 5, activation='relu'),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(stress_output_classes, activation='softmax', name='stress_output'),\n",
    "    layers.Dense(env_output_classes, activation='softmax', name='env_output')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# Train the model\n",
    "model.fit(X_train, {'stress_output': y_stress_train, 'env_output': y_env_train}, validation_data=(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test}), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "print(model.evaluate(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test}))\n",
    "\n",
    "# Prediction example\n",
    "sample_path = 'EmoSpeech/yes-scream-fearful-20190729211522-d14a028c2a3a2bc9476102bb288234c415a2b01f828ea62ac5b3e42f.wav'\n",
    "\n",
    "# Extract features from the sample\n",
    "sample_features = extract_features(sample_path)\n",
    "sample_features = np.expand_dims(sample_features, axis=0)\n",
    "\n",
    "# Predict stress and environment labels\n",
    "# stress_pred, env_pred = model.predict(sample_features)\n",
    "print(model.predict(sample_features)[0])\n",
    "\n",
    "# # Get the predicted labels\n",
    "# predicted_stress_index = np.argmax(stress_pred)\n",
    "# predicted_env_index = np.argmax(env_pred)\n",
    "# predicted_stress = label_encoder.inverse_transform([predicted_stress_index])[0]\n",
    "# predicted_env = label_encoder.inverse_transform([predicted_env_index])[0]\n",
    "\n",
    "# # Print predictions and class labels\n",
    "# print(f'Stress Prediction: {stress_pred}')\n",
    "# print(f'Environment Prediction: {env_pred}')\n",
    "# print(f'Predicted Stress: {predicted_stress}, Predicted Environment: {predicted_env}')\n",
    "\n",
    "# print(f'Predicted Stress: {predicted_stress}, Predicted Environment: {predicted_env}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-331.80505     83.01903     -0.8065515 ...   -5.7957993   -6.5359173\n",
      "     -6.778347 ]\n",
      "  [-286.3805      79.819916    -3.7666516 ...   -3.281063    -4.330223\n",
      "     -9.153894 ]\n",
      "  [-292.41898     83.718216    -6.4664483 ...   -4.276279    -2.1556718\n",
      "     -9.537165 ]\n",
      "  ...\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]\n",
      "  [   0.           0.           0.        ...    0.           0.\n",
      "      0.       ]]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Stress Prediction: 0.8799220323562622\n",
      "Environment Prediction: 0.05698821321129799\n",
      "Predicted Stress: glass break, Predicted Environment: glass break\n"
     ]
    }
   ],
   "source": [
    "# # # Get the predicted labels\n",
    "# stress_pred, env_pred, _, _x = model.predict(sample_features)[0]\n",
    "# predicted_stress_index = np.argmax(stress_pred)\n",
    "# predicted_env_index = np.argmax(env_pred)\n",
    "# predicted_stress = label_encoder.inverse_transform([predicted_stress_index])[0]\n",
    "# predicted_env = label_encoder.inverse_transform([predicted_env_index])[0]\n",
    "\n",
    "# # # Print predictions and class labels\n",
    "# print(f'Stress Prediction: {stress_pred}')\n",
    "# print(f'Environment Prediction: {env_pred}')\n",
    "# print(f'Predicted Stress: {predicted_stress}, Predicted Environment: {predicted_env}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "prob = model.predict(sample_features)\n",
    "classes = np.argmax(prob, axis = 1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
