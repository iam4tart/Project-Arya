{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import operator\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    data_ = []\n",
    "    count = {}\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        labels = file.split(\"-\")[:3]\n",
    "        data = {\n",
    "            \"keyword\": labels[0],\n",
    "            \"stress\": labels[2],\n",
    "            \"environment\": labels[1],\n",
    "            \"path\": os.path.join(path, file)\n",
    "        }\n",
    "        for label in labels:\n",
    "            if label not in count.keys():\n",
    "                count[label] = 1\n",
    "            else:\n",
    "                count[label] += 1\n",
    "        data_.append(data)\n",
    "    if data_:\n",
    "        df = pd.DataFrame(data_)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['keyword', 'stress', 'environment', 'path'])\n",
    "    return data_, count, df\n",
    "\n",
    "path = 'House/'\n",
    "dataset, count, df = get_files(path)\n",
    "df_nopath = df.iloc[:, :-1]\n",
    "\n",
    "print(count)\n",
    "print()\n",
    "print(df.head())\n",
    "print(\"Total Number of samples: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_foreground_and_mfcc(file_path, duration=3, sr=16000, n_mfcc=13, max_frames=150):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    \n",
    "    # Compute foreground and background\n",
    "    D = np.abs(librosa.stft(y))\n",
    "    S_full, _ = librosa.magphase(librosa.stft(y))\n",
    "    S_filter = librosa.decompose.nn_filter(S_full,\n",
    "                                           aggregate=np.median,\n",
    "                                           metric='cosine',\n",
    "                                           width=int(librosa.time_to_frames(1, sr=sr)))  # Adjusted width parameter\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "    margin_i, margin_v = 2, 10\n",
    "    power = 2\n",
    "    mask_i = librosa.util.softmask(S_filter,\n",
    "                                   margin_i * (S_full - S_filter),\n",
    "                                   power=power)\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter,\n",
    "                                   margin_v * S_filter,\n",
    "                                   power=power)\n",
    "    S_foreground = mask_v * S_full\n",
    "    \n",
    "    # Apply MFCC on foreground\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.amplitude_to_db(S_foreground), sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    # Pad or truncate to a fixed number of frames\n",
    "    if mfccs.shape[1] < max_frames:\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, max_frames - mfccs.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfccs = mfccs[:, :max_frames]\n",
    "    \n",
    "    return mfccs.T\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"your_audio_file_path.wav\"\n",
    "mfcc_features = extract_foreground_and_mfcc(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['stress_encoded'] = label_encoder.fit_transform(df['stress'])\n",
    "df['environment_encoded'] = label_encoder.fit_transform(df['environment'])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X = np.array([extract_features(file) for file in df['path']])\n",
    "y_stress = to_categorical(df['stress_encoded'])\n",
    "y_env = to_categorical(df['environment_encoded'])\n",
    "X_train, X_test, y_stress_train, y_stress_test, y_env_train, y_env_test = train_test_split(X, y_stress, y_env, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "input_shape = X_train.shape[1:]\n",
    "stress_output_classes = len(df['stress'].unique())\n",
    "env_output_classes = len(df['environment'].unique())\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(stress_output_classes, activation='softmax', name='stress_output'),\n",
    "    layers.Dense(env_output_classes, activation='softmax', name='env_output')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, {'stress_output': y_stress_train, 'env_output': y_env_train}, validation_data=(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test}), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "# Evaluate the model\n",
    "print(model.evaluate(X_test, {'stress_output': y_stress_test, 'env_output': y_env_test}))\n",
    "# loss, stress_loss, env_loss, stress_accuracy, env_accuracy = \n",
    "\n",
    "# print(f'Loss: {loss}, Stress Loss: {stress_loss}, Environment Loss: {env_loss}, Stress Accuracy: {stress_accuracy}, Environment Accuracy: {env_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction example\n",
    "sample_path = 'House/bacho-safe-calm-20190712132253.wav'\n",
    "sample_features = extract_features(sample_path)\n",
    "sample_features = np.expand_dims(sample_features, axis=0)\n",
    "stress_pred, env_pred = model.predict(sample_features)\n",
    "predicted_stress = label_encoder.inverse_transform([np.argmax(stress_pred)])\n",
    "predicted_env = label_encoder.inverse_transform([np.argmax(env_pred)])\n",
    "print(f'Predicted Stress: {predicted_stress}, Predicted Environment: {predicted_env}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectArya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
